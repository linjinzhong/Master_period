\chapter{网络话题的快速生成}\label{chap:topicGeneration}
\section{引言}

随着社交媒体的快速发展，越来越多的用户通过社交媒体来获取信息和分享观点。由此产生了海量的用户生成式数据，使得用户难以从中快速获取热点话题及感兴趣的话题。话题是某个种子事件及其相关报道的集合。网络话题检测任务自动地将网络数据组织成更多有意义的热门话题。从本质上来讲，网络话题检测就像从大海里捞针，类比从大量的网络数据中找到一小部分感兴趣数据并将其组织成热门事件。

传统的话题检测任务致力于将每个新闻文章分配到至少一个话题中。而这些经过专业编辑的新闻文章数据与网络数据存在极大的差异：由于社交媒体对所发布内容的约束较少，所以来自社交媒体的网络数据更加简短、稀疏并且充满噪声；在大量网页中，只有一小部分的网页能够被组织成热点话题。因此网络话题检测不仅面临着低效的特征表达还需要处理大量的噪声网页。

网络话题检测的关键问题是如何在海量噪声网页存在的前提下组织热点话题。一个直观的方法是在噪声网页存在的情况下去聚类网络话题。然而海量的噪声网页使得传统方法不再适用。为了移除大量噪声网页带来的不利影响，传统的方法采用了一种看似合理的假设，即在相同话题下的任意两个网页之间的相似度应该大于该话题中的网页和噪声网页之间的相似度。然而，这个假设也很难站得住脚，主要存在如下两个挑战：

\begin{enumerate}
\renewcommand{\labelenumi}{\theenumi)}
    \item 稀疏和充满噪声的网络数据导致低效的特征：用户生成式数据几乎没有约束，所以传统的适用于长文本的TF-IDF特征不足以高效表达社交媒体上稀疏的、充满噪声的网络数据。
    \item 低阶特征和高阶语义间存在的语义鸿沟：低阶的特征难以准确地表达高阶语义间的关系。所以网页之间更大的相似度值并不意味着这两个网页在语义上更加相似。
\end{enumerate}

在低效的特征表示以及海量噪声存在的前提下，我们寻找一种无关模型、无关优化的的方法来生成网络话题。首先是因为网络话题的结构和内容差异性很大，一个无模型的方法能拥有好的生成话题能力；其次，为了避免高复杂度的优化措施，一个无需优化的方法能够更好地处理大规模数据问题；然后，我们避免去处理短文本如何编码生成高效的特征表示这样一个开放性问题；最后网络话题面临着海量噪声。

我们研究了网络话题在相似度空间上的统计模式，发现同一个话题下的所有网页之间的相似度与L\'{e}vy Walks存在统计意义上的相似性。具体地，我们将网页之间的相似度类比为L\'{e}vy Walks中的步长，那么一个热点话题中的所有相似度分布大致服从重尾分布，而这重尾分布又是L\'{e}vy Walks中步长的特性。L\'{e}vy Walks是一种随机游走模型，其步长服从重尾概率分布。一次移动定义为一个质点从一个位置无偏移的移动到另一个位置的步长。直观上讲，L\'{e}vy Walks包含许多短步长的移动和一些逃脱短步长控制的额外较长步长的移动。因此，L\'{e}vy Walks可以用来很好地描述觅食动物的迁徙模式。

当L\'{e}vy Walks被用来组织网络话题，关键问题变成如下几点：
\begin{enumerate}
\renewcommand{\labelenumi}{\theenumi)}
    \item 如何在未知参数下模拟L\'{e}vy Walks中额外长的步长。
    \item 如何确定话题所需要的步长个数即网页个数。
    \item 在组织话题的时候选择这个步长是否能带来好处。
\end{enumerate}
基于上述三个问题，我们提出以下解决方案：
\begin{enumerate}
\renewcommand{\labelenumi}{\theenumi)}
    \item 提出基于L\'{e}vy Walks的话题生成算法（L\'{e}vy Walks-based Topic Generation，LWTG），该方法通过模拟L\'{e}vy Walks的特性，采用基于种子网页的多分配策略，优雅地避免了不同L\'{e}vy Walks需要不同参数的麻烦。简单的同时速度也很快。
    \item 提出多阈值方法来截断网络话题的生长，这会带来一系列过完备话题，从而提高话题的召回率。
    \item 至于话题召回准确率是由后续的排序算法来保证的。
\end{enumerate}

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.50\textwidth]{topic_generation_process.pdf}
    \caption{通过模拟L\'evy Walks来快速生成网络话题的流程图}
    \label{fig:topic_generation_process}
\end{figure}

本论文是第一个发现网络话题检测在相似度空间上和L\'{e}vy Walks具有相似的特点，并且进行了一系列实验来阐述这个发现所带来的好处。我们提出的LWTG方法不仅简单快速，而且能够进一步提高话题检测的召回率。通过简单地对网页进行分配，无需参数优化，我们找到了一种新的组织网络话题的方法。我们的方法在网络话题检测效率方面已经远超当前最好的方法，而且在话题检测召回率方面也能够赶上甚至超越当前最好的方法。算法框架如图\ref{fig:topic_generation_process}所示。

\section{相似度图的构建}

本章的研究重点是网络话题的生成，因此，为了减少其他因素的影响，我们忽略网络数据的多模态性和时间戳、链接等其他信息，只使用纯文本信息。所以每个网页就是一个文本字符串。对于给定的网络数据集，包含一系列的网页$W=\{w_1,...,w_N\}$,我们对其进行处理，生成一个$knn$近邻的相似度图$G=(V,E,A)$。其中顶点集$V$对应网页集合，仿射矩阵$A$对应截断后任意两个网页之间的相似度，边集$E$对应任意两个网页之间的非$0$边[xx]。具体处理如下。

首先，我们对网页的文本字符串进行分词，然后使用词袋模型[xx]对网页文本进行基本的统计和表示，再用TF-IDF特征值表示每个词的权重，这样每个网页就可以用一个特征向量$x_i\in \mathbb{R}^M(i=1,...,N)$表示。其中M是表示词典大小，N表示网络数据集中网页的数量。对于TF-IDF特征，TF表示词频，IDF表示逆文档频率。一个词在文档中出现的频率越高，其词频值越大，相应TF-IDF值就越大。与此同时，一个词如果出现在越多的文档中，则其逆文档频率值越低，相应TF-IDF特征值就越低。逆文档频率降低那些高频出现但是较没有判别意义的词的权重。比如：‘我’、‘那’这种指示代词几乎没有判别能力，虽然它们的词频值很大，但是它们的逆文档频率值很低，进而使得TF-IDF值很低。虽然还可以使用更高级的特征，但是语义鸿沟问题仍然存在，而且使用TF-IDF特征足够简单，能够带来更快的处理速度。

然后，基于得到的每个网页的特征向量，我们可以通过余弦距离来度量两个网页之间的相似度大小。在公式\ref{eq:cosinedistance}中，$S_{ij}$表示两个网页之间的相似度，$x_i$和$x_j$表示两个网页的特征向量：
\begin{equation}\label{eq:cosinedistance}
    S_{ij} = \frac{x_i\cdot x_j}{|x_i||x_j|}
\end{equation}

最后，得到相似度图后，在每个网页中，保留与其语义最相近的$knn$个网页关系，删除其他网页关系。这里假设两个网页之间相似度越高则语义越相近。这样做能够过滤掉大量网页之间的噪声干扰，即不相关的噪声网页。网络数据集中的噪声网页越多，$knn$应该选择更低的值。在公式\ref{eq:knn}中$KNN(w_i)$表示与网页$w_i$语义最相近的$knn$个网页集合。同时，我们使用公式\ref{eq:filtergraph}将两个网页之间低于某个阈值的相似度置为$0$，因为我们认为过低的相似度表示这两个网页在语义上已经没有关联关系了。这进一步过滤了噪声网页。
\begin{equation}\label{eq:knn}
S_{ij} = 
\begin{cases}
0, &  w_j \notin KNN(w_i) \\
S_{ij}, & w_j \in KNN(w_i)
\end{cases}
\end{equation}

\begin{equation}\label{eq:filtergraph}
S_{ij} = 
\begin{cases}
0, & S_{ij} < \epsilon \\
a_{ij}, & S_{ij} \geq \epsilon
\end{cases}
\end{equation}


\section{网络话题的L\'{e}vy Walks特性}
一个网络话题由未知数量的网页构成，在相似度空间上表示为一系列边$e_{ij}$经过仿射后的相似度$a_{ij}$，其中网页$x_i$和$x_j$属于该话题。话题的相似度空间包含两种相似度：1）话题内部相似度边：同个话题内部两个网页之间的相似度；2）话题之间相似度边：两个不在同个话题内的网页之间的相似度。

\begin{figure}[!htbp]
    \centering
    \begin{subfigure}[b]{0.24\textwidth}
      \includegraphics[width=\textwidth,height=0.8\textwidth]{fit_distribution_topic_1}
      \caption{}
      \label{fig:fitdistribution_t1}
    \end{subfigure}%
    % ~% add desired spacing
    \begin{subfigure}[b]{0.24\textwidth}
      \includegraphics[width=\textwidth,height=0.8\textwidth]{fit_distribution_topic_2}
      \caption{}
      \label{fig:fitdistribution_t2}
    \end{subfigure}
    % \\% line break
    \begin{subfigure}[b]{0.24\textwidth}
      \includegraphics[width=\textwidth,height=0.8\textwidth]{fit_distribution_topic_3}
      \caption{}
      \label{fig:fitdistribution_t3}
    \end{subfigure}%
    % ~% add desired spacing
    \begin{subfigure}[b]{0.24\textwidth}
      \includegraphics[width=\textwidth,height=0.8\textwidth]{fit_distribution_topic_4}
      \caption{}
      \label{fig:fitdistribution_t4}
    \end{subfigure}
    \caption{第1、2、3、4个话题分别最拟合指数韦伯分布，幂次分布，指数韦伯分布，幂次分布。}
    \label{fig:fitdistribution}
\end{figure}

\begin{figure}[!htbp]
    \centering
    \begin{subfigure}[b]{0.24\textwidth}
      \includegraphics[width=\textwidth,height=0.95\textwidth]{barGraph_topic_1}
      \caption{}
      \label{fig:barGraph_t1}
    \end{subfigure}%
    % ~% add desired spacing
    \begin{subfigure}[b]{0.24\textwidth}
      \includegraphics[width=\textwidth,height=0.95\textwidth]{barGraph_topic_2}
      \caption{}
      \label{fig:barGraph_t2}
    \end{subfigure}
    % \\% line break
    \begin{subfigure}[b]{0.24\textwidth}
      \includegraphics[width=\textwidth,height=0.95\textwidth]{barGraph_topic_3}
      \caption{}
      \label{fig:barGraph_t3}
    \end{subfigure}%
    % ~% add desired spacing
    \begin{subfigure}[b]{0.24\textwidth}
      \includegraphics[width=\textwidth,height=0.95\textwidth]{barGraph_topic_4}
      \caption{}
      \label{fig:barGraph_t4}
    \end{subfigure}
    \caption{已排序边的分布情况，包含话题内部的边和话题之间的边。}
    \label{fig:barGraph}
\end{figure}

\begin{table}[!htbp]
    \caption{常见的重尾分布函数。}
    \label{tab:PDF}
    \centering
    % \footnotesize% fontsize
    \setlength{\tabcolsep}{4pt}% column separation
    \renewcommand{\arraystretch}{1.2}%row space 
    \begin{tabular}{|c|c|}
        \hline
        分布函数 & 概率密度函数\\
        \hline\hline
        指数韦伯分布$^1$ & $(1-\exp(-\frac{x}{\lambda})^k)^{\alpha}$\\
        \hline
        锐利分布 & $\frac{x}{\sigma^2}\exp(\frac{-x^2}{2\sigma^2})$\\
        \hline
        韦伯分布$^2$ & $\frac{k}{\lambda}(\frac{x}{\lambda})^{k-1}\exp(-(\frac{x}{\lambda})^k)$\\
        \hline
        对数正态分布 & $\frac{1}{x\sigma\sqrt{2\pi}}\exp(-\frac{\ln(x)-\mu}{2\sigma^2})$\\
        \hline
        幂次分布　&　$a(cx)^{-k}$\\
        \hline
        帕累托分布$^3$　& $\frac{\alpha a^{\alpha}}{x^{\alpha+1}}$\\
        \hline
    \end{tabular}\\
    \footnotesize{$^1$ $\alpha \geq 1.$}\\
    \footnotesize{$^2$ $k < 1.$}\\
    \footnotesize{$^3$ $0 < a \leq x$}\\
\end{table}

我们从MCG-WEBV数据集中随机选择四个真实的网络话题来描述网络话题在相似度空间上的模式。对同个话题内部的相似度进行从大到小排序。图\ref{fig:fitdistribution}说明同个话题下的已排序的相似度服从重尾分布。从图\ref{fig:fitdistribution}引出两个问题：
\begin{enumerate}
\renewcommand{\labelenumi}{\theenumi)}
    \item 是否所有的话题服从相同的重尾分布？
    \item 服从相同分布的话题是否拥有相同的分布参数？ 
\end{enumerate}

为了解决上述问题，我们使用极大似然估计去将已排序的相似度拟合为已知的分布。例如：指数韦伯分布、锐利分布、韦伯分布、对数正态分布、幂次分布、帕累托分布。表\ref{tab:PDF}列出这些分布的概率密度函数。而且，为了量化最好的分布，我们引入赤池信息准则AIC（Akaike’s Information Criterion）[xxx]：
\begin{equation}\label{eq:AIC}
 AIC = -2log(L(\hat{\theta}|data)) + 2K   
\end{equation}
其中$L(\cdot)$是似然函数，K是参数的数量。由于AIC值容易受样本大小影响，不能被直接用来作为绝对的度量标准。所以，使用下面的转换形式作为每个模型的置信权重：
\begin{equation}\label{eq:AICweight}
    w_i = \frac{exp(-\Delta_i/2)}{\sum_{r=1}^{R}exp(-\Delta_r/2)}
\end{equation}
其中R是分布函数数量。赤池信息权重被认为是分布函数可能性的归一化值。

从图\ref{fig:fitdistribution}到\ref{fig:barGraph}，我们可以得到下面观察结果：
\begin{enumerate}
    \item[1)] 同个话题下网页之间的已排序的相似度与L\'{e}vy Walks存在统计意义上的相似特性。图\ref{fig:fitdistribution_t1}、\ref{fig:fitdistribution_t2}、\ref{fig:fitdistribution_t3}、\ref{fig:fitdistribution_t4}表明同个话题内的相似度服从重尾分布。
    \item[2)] 不同的话题服从不同的重尾分布。例如，根据赤池信息权重公式\ref{eq:AICweight}，图\ref{fig:fitdistribution_t1}所表示的第一个话题服从指数韦伯分布，而图\ref{fig:fitdistribution_t2}所表示的第二个话题服从幂次分布。
    \item[3)] 热点话题中包含一些额外的边。如图\ref{fig:barGraph}所示，如果话题的相似度按照递减排序，那么由边连接排在较前的网页，并不意味其绝对属于该话题。
\end{enumerate}

如果将相似度类比为网页之间的步长，那么与L\'{e}vy Walks相比，网络话题在相似度空间上有两个统计意义上的相似特性：1）L\'{e}vy Walks和网络话题的步长均服从重尾分布；2）L\'{e}vy Walks和网络话题均包含许多短的步长(高相似度)和一些额外长（低相似度）的步长。至此，这两个相似特性被认为是网络话题的L\'{e}vy Walks特性。

\section{通过模拟L\'{e}vy Walks生成话题}
既然网络话题有L\'{e}vy Walks特性，我们试图从这个特性入手，从海量网络数据中生成话题。一个最简单的办法是根据重尾分布来组织网页进入对应话题。然而，正如之前所言，我们不可能提前训练一个通用的含有重尾分布函数的模型。

通过在相似度空间利用重尾分布的特点，我们认为可以在将网页分配给话题的时候适当添加一定的随机性以模拟L\'{e}vy Walks中额外较长的步长。为此，我们设计了一种通过模拟L\'{e}vy Walks来生成话题的算法（L\'{e}vy Walks-based Topic Generation，LWTG）。LWTG算法的框架如图\ref{fig:LWTG}所示。
\begin{figure}[!htbp]
    \centering
    \includegraphics[width=1.0\textwidth]{LWTG.pdf}
    \caption{LWTG算法生成话题的框架图}
    \label{fig:LWTG}
\end{figure}

本论文中，我们提出两种度量网页和话题间相似度的方法，并将网页分配给相似度最高的$k$个话题来模拟网络话题在相似度空间中的L\'evy Walks特性：一些额外较低的相似度。

\subsection{寻找种子网页}
\begin{figure}[!htbp]
    \centering
    \includegraphics[width=1.0\textwidth]{similarity_cascade.pdf}
    \caption{基于相似度流的网络话题演化示意图}
    \label{fig:similarity_cascade}
\end{figure}
网络话题由初始核心事件不断在社交媒体上传播得以发展壮大。传播过程会逐渐吸收许多直接或者间接的外延信息。
网络话题的形成可以被看做是一种信息扩散的过程。而信息扩散的过程肯定会有一定的损失。我们使用相似度流来模拟这种信息扩散过程，扩散过程中信息的损失对应于相似度流中相似度值的较小。图\ref{fig:similarity_cascade}展示了网络话题基于相似度流的演化过程：话题初始时只有一两个网页，随后在较低的相似度上吸收更多的网页来形成更大的话题。随着演化的进行，吸收的网页的相似度越来越低。这种过程我们称之为相似度流扩散（Similarity Cascade, SC）。又因为不同用户之间的需求是不一样的，导致用户对话题的理解具有极大的差异。所以对同一个核心事件演化形成的话题，不同的用户所理解的话题的规模也是不一样的。

既然话题是由核心事件演化来的，那么我们希望能够通过代表该核心事件的种子网页，进而通过相似度流的扩散过程来模拟演化过程，最终生成话题。首要问题是如何判断一个网页能否作为种子网页？直观上理解，在一个由多个网页构成的话题中，其网页分布应该是尽可能均匀且紧凑的。均匀表示该话题内的网页之间的相似度较为接近，这是因为话题内的网页都是在为该话题服务的，所以它们应该是相似的，即相似度应该尽可能一致。紧凑表示该话题内的网页与话题应该是紧密相关，即相似度应该尽可能大。

受到论文[xxx]的启发，我们引进了站点熵率（Site Entropy Rate，SER）用来度量网页成为种子网页的概率。通过将相似度流从一个网页转移到另一个网页的过程模拟为全连接图中从一个站点转移到另一个站点的随机游走的过程，SER意味着从一个网页在一步内转移到其他网页的平均总信息转移量。而由种子网页吸收相似网页演化生成话题的过程中，越接近初始核心事件的网页，其通过相似度能够转移的平均总信息量也越大。SER的公式如下：
\begin{equation} \label{eq:SER}
SER_i = \pi_i\sum_{j\in<i>}-P_{ij}\log P_{ij}
\end{equation}
其中$P_{ij}=\frac{S_{ij}}{\sum_{j\in<i>}S_{ij}}$表示网页$w_i$转移到网页$w_j$的转移概率。$<i>\subset[1:N]$保存了s个与网页$w_i$最相似的网页索引。
公式\ref{eq:SER}表明SER可以被分为两个部分：稳态分布项和熵项。这两部分作用分别如下：
\begin{enumerate}
  \item[1)] 稳态分布项：$\pi_i = \frac{S_i}{S}$，其中$S_i=\sum_{j\in<i>}S_{ij}$是从网页$w_i$出发的所有相关相似度的和，$S = \sum_{i}\sum_{j\in<i>}S_{ij}$是相似度图中的所有网页及其最相似的s个网页的相似度的和。$\pi_i$被认为是网页$w_i$访问其他网页的频率；$\pi_i$越大，则表示由网页$w_i$经过一步演化的话题更加的紧凑；
  \item[2)] 熵项：$\sum_{j\in<i>}-P_{ij}\log P_{ij}$度量了网页$w_i$在一步内访问其他网页的不确定性。熵项越大，表明与网页$w_i$直接相连的其他网页的相似度分布更加均匀。
\end{enumerate}

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=1.0\textwidth]{seed_web_entropy.pdf}
    \caption{网页紧凑性和均匀性的SER评估}
    \label{fig:seed_web_entropy}
\end{figure}

SER由这两项的乘积构成。网页的SER越大，则表示其越有可能成为话题中的种子网页。如图\ref{fig:seed_web_entropy}所示，图中空心圈圈表示网页，红色实心圆圈表示要评估的网页，数字表示网页之间的相似度。从图（a）和图（b）可以看出在相同均匀分布的情况下（熵项一致），越紧凑的网页有更大的SER值。从图（c）和图（d）可以看出在相同紧凑性情况下（稳态分布项$\pi$一致），相似度分布越均匀的网页有更大的SER值。

在定义了SER作为网页成为种子网页的概率情况下，我们提出了一种基于关联度过滤的贪心算法来找到不同规模的种子网页。算法\ref{alg:greedysearchseedweb}展示整个搜索过程。算法的输入为相似度图，然后根据相似度图来计算每个网页的SER值。这里我们只需要选择与网页最相似的s个网页的相似度来计算SER值即可。因为SER仅用作一步内的相似度转移，而在一步内转移的网页应该是比较相似且数量比较少的，而不是全部的网页。所以这里我们只选择了s个最相似的网页来计算SER的值。另一个关联度参数d用来确定种子网页后，过滤与其最相似的d个网页。这么做是因为我们认为这d个最相似的网页可以在之后由该种子网页生长而得到。d值越大，产生的种子网页数量就越少。由于d值不好确定，同时为了更好地提高话题的召回率，我们使用多个不同的d值来产生多种规模的种子网页。算法输出为规模较小的种子网页集合。整个算法是基于SER值排序的贪心过滤算法：选择当前最优的种子网页，过滤与其最相似的d个网页，直到所有网页遍历结束。
\begin{algorithm}[!htbp]
    % \small
    \caption{基于关联度的种子网页贪心搜索算法}\label{alg:greedysearchseedweb}
    \hspace*{0.02in}{\bf Input:}
    相似度图 $G=(V,E,A)$，最相似网页个数$s$，关联度$d$\\
    \hspace*{0.02in}{\bf Output:}
    种子网页集合 $SW$，有序网页索引$SortedIndex$
    \begin{algorithmic}[1]
        % \State 初始化网页访问与否的的标记向量visit$\in \mathbb{R}^{N}$为False
        \State 初始化最终要生成的种子网页集合$SW$为空集
        \State 根据公式\ref{eq:SER}计算所有网页的SER
        \State 根据SER进行从大到小排序，得到有序且有连接的网页索引$SortedIndex$
        \State 找出与每个网页$w_i$最相似的$d$个网页索引,记为$\{i\}$
        \For{$i \in SortedIndex$}
        \If{网页$w_i$ 及其最相似的$d$个网页$w_{\{i\}}$ 未被访问} 
        \State $SW \leftarrow SW \bigcup w_i$
        \State 标记网页$w_i$及其最相似的$d$个网页$w_{\{i\}}$的状态为已访问
        \EndIf
        \EndFor
    \end{algorithmic}
\end{algorithm}


\subsection{网页多分配算法}

在产生种子网页后，我们提出了网页多分配算法来实现种子网页吸收相似网页，进而演化成话题。我们通过将网页分配给相似度最高的$k$个话题来模拟网络话题L\'evy Walks特性中额外较低的相似度。同时这个分配过程模拟了相似度流的扩散过程，所以我们采用了生成种子网页过程中产生的网页遍历顺序作为我们遍历网页的顺序。然后逐个进行网页分配。算法\ref{alg:multiallocateweb}展示了这个分配过程。其中对于每个待分配的网页，我们需要计算其与种子话题的相似度，希望这个相似度能够反映种子话题对网页的吸引程度。我们定义网页$w_i$对种子话题$C_s$的相似度为该网页所带来的平均相似度对比种子话题$C_s$当前平均相似度的比例。如公式\ref{eq:avgrate}。我们认为网页$w_i$如果能给种子话题$C_s$带来平均增加的相似度的比例越高，那么网页$w_i$与种子话题$C_s$必然更加密切相关。即网页$w_i$就有更大的可能性归属于该种子话题$C_s$。
\begin{equation}\label{eq:avgrate}
  S_{is} = \frac{\text{Avg}\big(\sum_{j\in C_s}(a_{ij}+a_{ji})\big)}{\text{Avg}(C_s)}
\end{equation}


\begin{algorithm}[!htbp]
    % \small
    \caption{基于种子网页的网页多分配算法}\label{alg:multiallocateweb}
    \hspace*{0.02in}{\bf Input:}
    相似度图$G=(V,E,A)$，网页索引$SortedIndex$，种子网页集合$SW$，$k$\\
    \hspace*{0.02in}{\bf Output:}
    一系列话题集合$C$
    \begin{algorithmic}[1]
        \State 初始化空的话题集合C
        \State 初始化种子话题$C_s$($s\in SW$)及对应的阈值$th_s=1$
        \For{$i \in SortedIndex$}
        \State 计算网页$w_i$与每个种子话题$C_s$的相似度$S_{is}$
        \State $\{i\} \leftarrow \operatorname*{argmaxk}\limits_{s\in SW}(S_{is}, k)$\Comment{取与网页$w_i$最相似的$k$个种子话题的索引}
        \For{$s \in \{i\}$}
        \If{$IsCut(C_s, w_i, th_s)}$
        \State $C \leftarrow C \bigcup C_s$
        \State $C_s \leftarrow C_s \bigcup w_i$
        \State $th_s = \lfloor{\text{Avg}(C_s)\times10}\rfloor\div 10$
        \EndIf
        \EndFor
        \EndFor
    \end{algorithmic}
\end{algorithm}

得到网页与种子话题的相似度后，我们将网页分配给相似度最高的$k$个种子话题。公式\ref{eq:iscut}实现了函数$IsCut(\cdot)$，其中$th$使用了多层阈值来截断产生过完备的话题。阈值$th$在每一轮更新种子话题后重新赋值为当前种子平均相似度所处的层。比如说，之前种子话题的平均相似度$Avg(C_s)=0.76$，那么该种子话题所处的相似度层的阈值为$th=0.7$。如果新加的网页使得种子话题的平均相似度$Avg(C_s\cup w_i)=0.63$，那么由于更新后的种子话题不再属于原相似度层（即$0.63<0.7$），启动阈值截断，即将之前的种子话题作为生成的完整话题加入到话题集合中去。同时，更新当前相似度层阈值为$th=0.6$。
\begin{equation} \label{eq:iscut}
IsCut(\cdot) = 
\begin{cases}
1, & \text{Avg}(C_s\cup w_i) < th\\
0, & otherwise\\
\end{cases}
\end{equation}

基于上述两个算法，我们可以得到通过模拟L\'evy Walks来生成话题的算法\ref{alg:LWTG}。
\begin{algorithm}[!htbp]
    % \small
    \caption{基于L\'evy Walks的话题生成算法}\label{alg:LWTG}
    \hspace*{0.02in}{\bf Input:}
    相似度图$G=(V,E,A)$，最相似网页个数$s$，关联度集合D, 分配话题数$k$\\
    \hspace*{0.02in}{\bf Output:}
    过完备话题集合$C$ 
    \begin{algorithmic}
        \For{$d \in D$}
            \State 使用算法\ref{alg:greedysearchseedweb}\qquad \qquad \textbf{/* 寻找种子网页 */}
            \State 使用算法\ref{alg:multiallocateweb}\qquad \qquad \textbf{/* 通过网页多分配算法生成话题 */}
        \EndFor
    \end{algorithmic}
\end{algorithm}

\subsection{话题排序}

一旦相似度图$G(V,E,A)$构建完，我们通过算法\ref{alg:LWTG}生成候选话题集合。然后我们在泊松噪声的假设下，使用泊松去卷积算法（Poisson Deconvolution，PD）来评估每个话题的权重：
\begin{align} \label{eq:poisondeconvolution}
w_{ij} &\sim \textbf{Poisson}(a_{ij})\notag\\
s.t.: w_{ij} &= \sum_{k=1}^{K}\mu_kC_{k_{ij}}
\end{align}
其中$C_{k_{ij}}$表示第$k$个话题是否同时包含网页$w_i$和$w_j$。话题的兴趣度由$i_k=\mu_k\cdot|C_k|$计算得到，其中$C_k$是第$k$个话题包含的网页数量。具体细节参见章节\ref{chap:topicsSort}。




\subsection{时间复杂度分析}

我们提出的算法\ref{alg:LWTG}是基于L\'evy Walks的话题生成算法。主要包含寻找种子网页和网页多分配算法两部分。采用多粒度种子策略，其中$D$是种子网页的关联度集合，集合$D$的个数通常小于$10$。关联度越大，种子网页数量越少，通常从$1\sim10$中选取。

在寻找种子话题过程中，我们需要在只保留$knn$个近邻的相似度图中计算每个网页的SER值以及过滤相关网页，时间复杂度分别为：
\begin{itemize}
  \item 计算SER： $O(s\cdot knn\cdot N)$；
  \item 过滤网页： $O(d\cdot knn\cdot N)$；
\end{itemize}
其中$N$是网页总数。$knn$是每个网页要保留的近邻数,通常来说$knn$小于$100$。$s$是最相似的网页个数，通常小于$20$；d是要过滤的最相似网页个数（关联度），通常小于$10$。而对于大规模网络数据而言，网页数量通常是巨大的。所以综上可以得到寻找种子网页的时间复杂度为近似线性的$O(knn\cdot N)$。

在基于种子网页的网页多分算法中，我们需要针对每个网页计算两部分内容，分别是网页与种子话题的相似度以及网页分配给种子话题，时间复杂度分别是：
\begin{itemize}
  \item 计算网页和种子话题的相似度： $O(|topic|\cdot |SW|\cdot N)$；
  \item 将网页分配给k个话题： $O(k\cdot N)$；
\end{itemize}
其中$N$是网页总数。$|topic|$表示话题内包含的网页个数，通常小于$100$。$|SW|$是种子网页（种子话题）个数。
$k$是要分配的网页个数，通常小于$5$。所以综上可以得到网页多分配算法的时间复杂度为$O(|SW|\cdot N)$

从上面时间复杂度分析可以看出在算法\ref{alg:LWTG}中，基于种子网页的网页多分配算法占据主要的时间复杂度。因此我们提出的LWTG算法的时间复杂度为$O(|SW|\cdot N)$。种子网页的个数$SW$小于网页数$\frac{N}{2}$。这个时间复杂度对于大规模的网络数据来说是非常高效的。



\section{实验验证}
本节对我们提出LWTG算法在MCG-WEBV和YKS这两个数据集上展开实验。主要进行两方面的比较。第一个是跟两个最好的能够处理噪声数据的聚类算法进行对比；第二个是跟其他三个最好的网络话题检测算法进行对比。通过这两类对比来验证我们算法的性能。

\subsection{数据预处理}

对于MCG-WEBV数据集，我们使用其中的文本数据包括标题、标签和描述。首先过滤掉文本数据中的停用词，由于该数据集基本由英文构成，所以使用Python中的NLTK模块，对每个单词提取词干、统计tf-idf值作为单词权重，最后由tf-idf值生成每个网页的特征向量。

对于YKS数据集，基本由中文组成。所以需要采用NLPIR系统对文本数据进行预处理，包括分词、去停用词、处理同义词和扩展词等，然后统计每个词的tf-idf的值，再对每个网页生成特征向量。

\subsection{评测标准}
在评测标准上，我们使用以下两种评测指标：
\begin{itemize}
  \item 最高10个检测话题的$F_1$分数的均值-检测的话题数量（Top-10 $F_1$ v.s. Number of Detected Topics，NDT）：对于每个检测得到的话题$D_t$，对应其最高匹配程度的真实标注的话题$G_t$，我们可以定义话题精确度$Precision$的公式\ref{eq:Precision}、话题召回率$Recall$的公式\ref{eq:Recall}和话题$F_1$的分数公式\ref{eq:F1}:
  \begin{align}
    \label{eq:Precision} Precision &= \frac{|D_t| \bigcap |G_t|}{|D_t|}\\
    \label{eq:Recall} Recall &= \frac{|D_t| \bigcap |G_t|}{|D_t| \bigcup |G_t|}\\
    \label{eq:F1} F_1 &= \frac{2\times Precision \times Recall}{Precision + Recall}
  \end{align}
  其中$|\cdot|$表示一个话题中的网页数目。

  \item 准确率-平均到每个话题上的误检率（$Accuracy$ v.s. False Positives Per Topics,$FPPT$）：准确率$Accuracy$的公式为\ref{eq:Accuracy}，$FPPT$的公式为\ref{eq:FPPT}:
  \begin{align}
    \label{eq:Accuracy} Accuracy &= \frac{\#Successful}{\#Groundtruth} \\
    \label{eq:FPPT} FPPT &= \frac{\#Detected - \#Successful}{\#Successful}
  \end{align}
  其中话题被认为是正确检测到的标准由NIR（Normalized Intersected Ratio）指标衡量。NIR指标定义为公式\ref{eq:NIR}：
  \begin{equation}\label{eq:NIR}
    NIR = \frac{|D_t| \bigcap |G_t|}{|D_t| \bigcup |G_t|}
  \end{equation}
  当检测到的话题的$NIR$高于一定阈值（通常设为0.5）[xx]时，我们认为这是一个正确检测到的话题。对于$\# \triangle$表示对应集合$\triangle$的元素数量。
\end{itemize}

对于这两种评测指标，Top-10 $F_1$ v.s. NDT衡量算法检测到的最好的前10个话题的性能，但是并没有考虑到检测过程带来的误检率。而$Accuracy v.s. FPPT$综合衡量了所检测到的话题的准确率以及相应的平均每找到一个正确话题所带来的误检数。在这两种指标中，当具有相同Top-10 $F_1$分数或准确率时，更低NDT或FPPT的算法具有更优的话题检测性能。

\subsection{实验设置}

在实验中，我们选择了网页的文本数据进行词汇的tf-idf统计和编码，然后使用余弦距离构建相似度图。最后对每个网页只保留最相似的$knn$个网页的相似度值构建一个近邻
图。这里对MCG-WEBV数据集的$knn$设为100，最相似网页个数s设为10。对YKS数据集，由于噪声相比MCG-WEBV数据集更严重，所以近邻值$knn$设为15，最相似网页个数s设为15。在所有实验中，同时在相似度图上过滤噪声网页的阈值$\epsilon$设为0.1。跟种子粒度相关的关联度参数集合$D$设为${1,2,3,4}$。网页多分配的话题数$k$为2。

\subsection{与聚类算法的对比}

我们对比了LWTG算法与两个性能最好的能够处理噪声数据的聚类算法：
\begin{enumerate}
  \item[a)] \textbf{Robust Spectral Clustering (RSC) for noisy data [xx].} 这篇论文通过对相似度图的稀疏和隐式分解来处理噪声。然而，这种方法假设了噪声是稀疏的，但是在网络话题检测的场景下，大概$95\%$的数据都是噪声数据。
  \item[b)] \textbf{Skinny-Dip (SD) [xx].} SD基于检验分布是否为单峰分布的Hartigan’s elegant dip test，从而得到一个有效的特征集来聚类。
\end{enumerate}

注意到RSC和SD算法不是为了检测网络话题而是为了从噪声数据中进行聚类。所以对于RSC，SD和LWTG的对比，主要是为了验证能处理噪声数据的聚类算法，能否有效地在海量噪声数据中检测到网络话题。在下面的实验中，对RSC，聚类个数设为真实话题个数。如MCG-WEBV数据集的$73$个真实话题和YKS数据集的$298$个真实话题。对于SD，聚类个数由算法自动确定。

图\ref{fig:MCG_Accuracy_CMP_denoise}和图\ref{fig:MCG_Top10_CMP_denoise}表明我们的方法优于SD和RSC方法。从图中可以看出SD算法的$Accuracy$和Top10-$F_1$几乎为0。这是因为在MCG-WEBV数据集中，TF-IDF特征的维度是9,212，这使得SD方法难以有效地从高维和充满噪声的特征中发现聚类。同时，注意到RSC方法在$Accuracy$上跟我们的算法结果相差不大，但是，在Top10-$F_1$上却差很多。这是因为由RSC生成的聚类的质量受到大量噪声的影响。而我们的方法不需要复杂的模型构建和优化就能在这两种评测标准上都能取得更好的结果。

图\ref{fig:YKS_Accuracy_CMP_denoise}和图\ref{fig:YKS_Top10_CMP_denoise}进一步在YKS数据集上对比我们的方法和RSC、SD方法。注意到SD方法没有被画出来，这是因为YKS数据集的特征维度高达80,294，使得SD方法无法返回任何聚类。图\ref{fig:YKS_Accuracy_CMP_denoise}和图\ref{fig:YKS_Top10_CMP_denoise}表明我们的方法在YKS数据集上仍然比RSC和SD方法好。
\begin{figure}[!htbp]
    \centering
    \begin{subfigure}[b]{0.5\textwidth}
      \includegraphics[width=\textwidth,height=0.8\textwidth]{MCG_Accuracy_CMP_denoise}
      \caption{}
      \label{fig:MCG_Accuracy_CMP_denoise}
    \end{subfigure}%
    % ~% add desired spacing
    \begin{subfigure}[b]{0.5\textwidth}
      \includegraphics[width=\textwidth,height=0.8\textwidth]{MCG_Top10_CMP_denoise}
      \caption{}
      \label{fig:MCG_Top10_CMP_denoise}
    \end{subfigure}
    % \\% line break
    \begin{subfigure}[b]{0.5\textwidth}
      \includegraphics[width=\textwidth,height=0.8\textwidth]{YKS_Accuracy_CMP_denoise}
      \caption{}
      \label{fig:YKS_Accuracy_CMP_denoise}
    \end{subfigure}%
    % ~% add desired spacing
    \begin{subfigure}[b]{0.5\textwidth}
      \includegraphics[width=\textwidth,height=0.8\textwidth]{YKS_Top10_CMP_denoise}
      \caption{}
      \label{fig:YKS_Top10_CMP_denoise}
    \end{subfigure}
    \caption{LWTG算法和聚类算法RSC、SD的对比}
    \label{fig:MCG_CMP_denoise}
\end{figure}

总之，从话题生成质量来看，在生成相同话题情况下，我们提出的LWTG方法在$Accuracy$和Top10-$F_1$上均比RSC和SD方法取得更好的结果。

表\ref{tab:denoisy_time_cmp}进一步在3.6Hz CPU和32G内存的电脑上对比了RSC、SD和LWTG算法的运行时间。从表中可以看出我们的LWTG算法的话题召回率远远高于RSC算法。因为我们的算法通过种子网页模拟了网络话题的L\'evy Walks特性，从而保证了话题检测系统的召回率。

我们同时还注意到当网页从MCG数据集的3,600增长到YKS数据集的8,660的时候，RSC算法花了超过15x（如：125/8）倍的时间。作为对比，我们的LWTG算法使用了大概5x（如：333/73）倍的时间。
\begin{table}[!htbp]
    \caption{不同话题生成算法的运行时间（秒）和系统准确率（$Accuracy$）对比}
    \label{tab:denoisy_time_cmp}
    \centering 
    \begin{tabular}{|c|c|c|c|}
    % \begin{tabular}{|p{4cm}<{\centering}|p{1cm}<{\centering}|p{1cm}<{\centering}|p{2.5cm}<{\centering}|p{1cm}<{\centering}|p{3cm}<{\centering}|}
        \hline
        Data set(\#webpages) & LWTG($Accuracy$) & RSC($Accuracy$) & SD($Accuracy$)\\
        \hline
        \hline
        MCG-WEBV(3660) & $73(\mathbf{0.88})$ & $\mathbf{8}(0.35)$ & $20(0.02)$\\
        \hline
        YKS(8660) & $333(\mathbf{0.77})$ & $\mathbf{125}(0.40)$ & $152(0.00)$\\
        \hline
    \end{tabular}
\end{table}

总之，从话题生成效率来看，虽然我们的LWTG算法比RSC算法更慢。但是，当网页数量不断增加时，RSC算法比LWTG算法更加敏感。


\subsection{与网络话题检测算法的对比}

我们对比了LWTG算法与3个性能最好的网络话题检测算法：
\begin{enumerate}
  \item[a)] \textbf{Multi-Modality Graph (MMG) [xx].} 该算法属于多模态网络话题检测。Zhang等人首先利用视频的NDK信息和文本信息建立相似度图[xx]，然后使用图转移算法[xx]进行话题检测。MMG假定了一个话题内的元素应该密切相关，所以，通常情况下MMG产生的话题规模较小。
  \item[b)] \textbf{PD with Non-negative Matrix Factorization on Graph
(NMFG) [xx].} NMFG和LWTG最大的不同的是产生话题的方式。NMFG中使用基于图的非负矩阵分解（Non-negative Matrix factorization on Graph，NMG）[xx]在相似度级联上生成过完备话题。NMG在无噪声数据下的聚类非常耗时。
  \item[c)] \textbf{Latent Poisson Deconvolution (LPD) [xx].} LPD算法在MCG-WEBV数据集和YKS数据集上均达到了当前最好的性能。相比单纯在PD上使用单一近邻图的方法，LPD利用多个近邻图来排序话题。这个证明了我们的方法可以在不利用多个近邻图的情况下达到可接受的结果。
\end{enumerate}
为了尽可能公平的进行对比，在每个数据集上，我们使用了相同的实验设置。
\begin{enumerate}
  \item[1)] \textbf{在MCG-WEBV上进行网络话题生成:} 图\ref{fig:MCG_CMP_webtopics}展示了在MCG-WEBV数据集上，我们的LWTG算法和当前最好的几个网络话题检测算法的对比结果。从图中可以得出以下结论：
  \begin{itemize}
    \item 当FPPT大于8时，LWTG算法显著优于NMFG算法[xx]，几乎能媲美LPD算法[xx]。但是我们要注意到LPD算法使用非常耗时但是非常有效的NMG算法[xx]，从两个$k$近邻图中生成话题。而NMFG算法[xx]也使用NMG算法[xx]来生成话题。作为对比，我们提出的无模型的无需优化的LWTG算法避免去设计复杂的模型及其优化。
    \item 当FPPT小与8或者NDT大于200时，LWTG算法稍微弱于NMFG算法和LPD算法。主要原因是泊松去卷积算法错误地将不正确的话题排在了正确话题的前面。
  \end{itemize}

  就话题生成效率来看，表\ref{tab:webtopics_time_cmp}展示了NMFG和LPD算法的运行时间分别是LWTG算法的71x(如：5248/73)和158x（如：11545/73）倍。这意味着我们的LWTG算法非常有希望能很好地对大规模网络数据进行基于泊松去卷积算法的话题检测，与此同时，LWTG算法的话题生成质量也比得上当前最优秀的算法。
  \begin{figure}[!htbp]
    \centering
    \begin{subfigure}[b]{0.5\textwidth}
      \includegraphics[width=\textwidth,height=0.8\textwidth]{MCG_Accuracy_CMP_webtopics}
      \caption{}
      \label{fig:MCG_Accuracy_CMP_webtopics}
    \end{subfigure}%
    % ~% add desired spacing
    \begin{subfigure}[b]{0.5\textwidth}
      \includegraphics[width=\textwidth,height=0.8\textwidth]{MCG_Top10_CMP_webtopics}
      \caption{}
      \label{fig:MCG_Top10_CMP_webtopics}
    \end{subfigure}
    \caption{LWTG算法和当前最优网络话题检测算法在MCG-WEBV数据集上的对比}
    \label{fig:MCG_CMP_webtopics}
  \end{figure}

  \begin{table}[!htbp]
      \caption{不同话题生成算法的运行时间（秒）和话题数量对比}
      \label{tab:webtopics_time_cmp}
      \centering 
      \begin{tabular}{|c|c|c|c|c|}
      % \begin{tabular}{|p{4cm}<{\centering}|p{1cm}<{\centering}|p{1cm}<{\centering}|p{2.5cm}<{\centering}|p{1cm}<{\centering}|p{3cm}<{\centering}|}
          \hline
          Data set(\#topic) & LWTG(\#topic) & LPD(\#topic) & NMFG(\#topic) & MMG(\#topic)\\
          \hline
          \hline
          MCG-WEBV(3660) & $\mathbf{73}(\mathbf{2504})$ & $11545(7685)$ & $5248(4238)$ & $15(430)$\\
          \hline
          YKS(8660) & $\mathbf{333}(7458)$ & $29321(7524)$ & $13847(\mathbf{5714})$ & 2$52(445)$\\
          \hline
      \end{tabular}
  \end{table}

  \item[2)] \textbf{在YKS数据集上进行网络话题生成:} YKS是一个跨平台的数据集，比MCG-WEBV数据集包含更多不同类型的话题，也更有挑战性。图\ref{fig:YKS_CMP_webtopics}进一步说明了当FPPT大于8时，我们提出的LWTG算法仍然显著优于当前最好的话题检测算法。

  同时就话题生成效率来看，表\ref{tab:webtopics_time_cmp}展示了NMFG和LPD算法的运行时间分别是LWTG算法的41x(如：13847/333)和88x（如：29321/333）倍。这意味着我们的LWTG算法非常有希望能很好地对大规模网络数据进行基于泊松去卷积算法的话题检测。虽然MMG算法的运行时间比较低，但是该算法对网页数量非常敏感。比如说当网页MCG-WEB数据集的3,660增长到YKS数据集的8,660的时候，MMG算法的运行时间超过了16x（如：252/15）倍。同时，MMG算法生成的话题质量也远远不如其他几个算法。

  \begin{figure}[!htbp]
    \centering
    \begin{subfigure}[b]{0.5\textwidth}
      \includegraphics[width=\textwidth,height=0.8\textwidth]{YKS_Accuracy_CMP_webtopics}
      \caption{}
      \label{fig:YKS_Accuracy_CMP_webtopics}
    \end{subfigure}%
    % ~% add desired spacing
    \begin{subfigure}[b]{0.5\textwidth}
      \includegraphics[width=\textwidth,height=0.8\textwidth]{YKS_Top10_CMP_webtopics}
      \caption{}
      \label{fig:YKS_Top10_CMP_webtopics}
    \end{subfigure}
    \caption{LWTG算法和当前最优网络话题检测算法在YKS数据集上的对比}
    \label{fig:YKS_CMP_webtopics}
  \end{figure}
\end{enumerate}


\section{小结}

本章介绍了一种面向网络数据的快速生成网络话题的算法，有望解决基于大规模网络数据的话题检测问题。该算法通过对网页计算话题概率值生成多粒度的种子网页，然后模拟L\'evy Walks特性，基于网页-话题的相似度，采用一种网页多分配算法来生成话题，同时使用层级阈值来截断话题生成一系列过完备的话题。最后的实验从话题生成质量以及话题生成效率两方面验证了我们提出的LWTG算法的优越性。

